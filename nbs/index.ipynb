{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot-Feature-Space\n",
    "\n",
    "> Demonstrating geometrical phenomena in feature spaces of few-shot learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Collapse (https://arxiv.org/abs/2008.08186) is a phenomenon where after enough traning, a model's feature space presents a specific geometrical structure, namely small intra-class variation, and class means that form a simplex ETF structure.\n",
    "In this work we aim to demonstrate that similar-but-different properties arise in featur extractors used for few-shot learning (e.g. pair matching using Siamese networks), for classes unseen during training.\n",
    "\n",
    "Specifically, we see that $d$-dimensional feature vectors of class $C$ distribute as $\\mathcal{N}(\\mu_C, \\sigma^2)^d$, where $\\mu_C$ distributes uniformly on a unit-sphere in some $k$-dimensional subspace.\n",
    "Assuming \"ideal class samples\" (prototypes) indeed distribute uniformly on some feature sphere, and the intra-class variablity distributes normally in that same space, we can deduce that the learning process correctly identifies this set of features (and other redundant ones) based on the classes seen during training, which would naturally lead to good generalization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sidebar you'll find differnet links to different pages, demonstrating the differnet geometrical properties:\n",
    "\n",
    "* `Normal Distribution` shows that the class means, and the off-centroid points in each class, distribute normally\n",
    "* `Class Mean PCA` shows that class means effectively reside in a low-dimensional subspace\n",
    "* `Inter-Class` shows that class means tend to be orthogonal to one another\n",
    "* `Intra-Class` shows that classes tend to be tightly concentrated (angle-wise). Together with the previous property, this explains the effectiveness of such feature extractors as bakbones for Siamese Netowrks (since inter-class and intra-class angles are separable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "git clone https://github.com/Irad-Zehavi/Few-Shot-Feature-Space.git\n",
    "cd Few-Shot-Feature-Space\n",
    "pip install .\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
