# Few-Shot-Feature-Space

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

Neural Collapse (https://arxiv.org/abs/2008.08186) is a phenomenon where
after enough traning, a model’s feature space presents a specific
geometrical structure, namely small intra-class variation, and class
means that form a simplex ETF structure. In this work we aim to
demonstrate that similar-but-different properties arise in featur
extractors used for few-shot learning (e.g. pair matching using Siamese
networks), for classes unseen during training.

Specifically, we see that $d$-dimensional feature vectors of class $C$
distribute as $\mathcal{N}(\mu_C, \sigma^2)^d$, where $\mu_C$
distributes uniformly on a unit-sphere in some $k$-dimensional subspace.
Assuming “ideal class samples” (prototypes) indeed distribute uniformly
on some feature sphere, and the intra-class variablity distributes
normally in that same space, we can deduce that the learning process
correctly identifies this set of features (and other redundant ones)
based on the classes seen during training, which would naturally lead to
good generalization.

In the sidebar you’ll find differnet links to different pages,
demonstrating the differnet geometrical properties:

- `Normal Distribution` shows that the class means, and the off-centroid
  points in each class, distribute normally
- `Class Mean PCA` shows that class means effectively reside in a
  low-dimensional subspace
- `Inter-Class` shows that class means tend to be orthogonal to one
  another
- `Intra-Class` shows that classes tend to be tightly concentrated
  (angle-wise). Together with the previous property, this explains the
  effectiveness of such feature extractors as bakbones for Siamese
  Netowrks (since inter-class and intra-class angles are separable)

## Install

``` sh
git clone https://github.com/Irad-Zehavi/Few-Shot-Feature-Space.git
cd Few-Shot-Feature-Space
pip install .
```
